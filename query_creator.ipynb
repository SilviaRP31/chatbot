{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "merchants = [\"Adidas\",\"Airbnb\",\"Aliexpress\",\"Amazon\",\"Apple Store\",\"ASOS\",\"Bath & Body Works\",\"Booking.com\",\"Boots\",\"Burger King\",\"Carrefour\",\"Chipotle\",\"Costa Coffee\",\"Decathlon\",\"Dia\",\"Domino's Pizza\",\n",
    "              \"Dunkin' Donuts\",\"El Corte Inglés\",\"Etsy\",\"Expedia\",\"Fnac\",\"Groupon\",\"H&M\",\"Ikea\",\"KFC\",\"La Caixa\",\"Lidl\",\"Lonely Planet\",\"Mango\",\"McDonald's\",\"MediaMarkt\",\"Mercadona\",\"Netflix\",\n",
    "              \"Nike\",\"Panera Bread\",\"Papa John's\",\"Patagonia\",\"Pizza Hut\",\"Red Lobster\",\"Repsol\",\"Samsung Store\",\"Santander\",\"Sephora\",\"Skyscanner\",\"Spotify\",\"Starbucks\",\"Subway\",\"The North Face\",\n",
    "              \"Thomas Cook\",\"TGI Fridays\",\"TripAdvisor\",\"TUI\",\"Uber\",\"Vinted\",\"Wish\",\"Zalando\",\"Zara\"]\n",
    "tags = [ \"moda\",\"e-commerce\",\"viajes\",\"belleza\",\"electrónica\",\"farmacia\",\"restaurante\",\"alojamiento\",\"deportes\",\"servicios\",\"supermercado\",\"banca\",\"cafetería\",\"transporte\",\"entretenimiento\",\"tienda\",\"combustible\"]\n",
    "cities = [\"Madrid\",\"Sevilla\",\"Barcelona\",\"Valencia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Ruta del archivo CSV (ajusta según tu configuración)\n",
    "archivo_csv = \"transactions.csv\"\n",
    "\n",
    "# Nombre de la columna que deseas extraer\n",
    "merchant = \"Merchant\"\n",
    "tags = \"Tag1;Tag2;Tag3\"\n",
    "cities = \"City\"\n",
    "\n",
    "# Lista para almacenar los datos de la columna\n",
    "merchants = []\n",
    "tags = []\n",
    "cities = \"City\"\n",
    "try:\n",
    "    # Abrir y leer el archivo CSV\n",
    "    with open(archivo_csv, mode='r', encoding='utf-8') as archivo:\n",
    "        lector = csv.DictReader(archivo)  # Lee el archivo como un diccionario\n",
    "        for fila in lector:\n",
    "            # Agregar el valor de la columna deseada a la lista\n",
    "            merchants.append(fila[merchant])\n",
    "\n",
    "    # Mostrar los datos obtenidos\n",
    "    print(f\"Datos de la columna '{columna_deseada}':\", lista_datos)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo '{archivo_csv}' no fue encontrado.\")\n",
    "except KeyError:\n",
    "    print(f\"La columna '{columna_deseada}' no existe en el archivo CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import re\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, SafetySetting\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def handle_input(input_string):\n",
    "  # Check for date and/or amount\n",
    "  month_match = re.search(r\"\\b(january|february|march|april|may|june|july|august|september|october|november|december|enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre|año|year)\\b\", input_string.lower())\n",
    "  number_match = re.search(r'\\d+', input_string)\n",
    "\n",
    "  # Check for Tag and City mentions in the input\n",
    "  tag_keywords = [\"tag1\", \"tag2\", \"tag3\"]  # List of possible tag columns\n",
    "  city_keywords = [\"city\"]  # List for city\n",
    "  merchant_keywords = [\"merchant\"] #List of merchant\n",
    "\n",
    "  # Check if any tag or city keywords are in the input\n",
    "  tags_detected = any(tag in input_string.lower() for tag in tag_keywords)\n",
    "  city_detected = any(city in input_string.lower() for city in city_keywords)\n",
    "  merchant_detected = any(merchant in input_string.lower() for merchant in merchant_keywords)\n",
    "\n",
    "  # Check for multiple columns (Tag + City)\n",
    "  columns = re.findall(r'(\\w+): (\\w+)', input_string)\n",
    "\n",
    "  # If we detect both tag and city information, classify as NL2Q\n",
    "  if (tags_detected and merchant_detected and city_detected) or (tags_detected and city_detected) or (tags_detected and merchant_detected) or (city_detected and merchant_detected) or number_match or month_match:\n",
    "    return \"NL2Q\"  # Matches multiple columns (e.g., Tag and City) and date/amount\n",
    "  else:\n",
    "    return \"StringMatching\"  # Matches only one column or no clear pattern\n",
    "\n",
    "def filter_input(input_string, merchants, tags, cities):\n",
    "    # Split the input into words\n",
    "    words = input_string.split()\n",
    "\n",
    "    # Filter words based on known categories (merchants, tags, cities)\n",
    "    filtered_words = [\n",
    "        word for word in words\n",
    "        if word in merchants or word in tags or word in cities\n",
    "    ]\n",
    "\n",
    "    return filtered_words\n",
    "\n",
    "# Configuración para generar consultas SQL\n",
    "def generate(user_input,process):\n",
    "    vertexai.init(project=\"go-agl-poc-itedt-p01-poc\", location=\"europe-west4\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-002\",\n",
    "        system_instruction=[process]\n",
    "    )\n",
    "\n",
    "    # Generar la consulta basada en la entrada del usuario\n",
    "    responses = model.generate_content(\n",
    "        [user_input],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    # Capturar el texto de la respuesta generada\n",
    "    query_text = \"\"\n",
    "    for response in responses:\n",
    "        query_text += response.text\n",
    "\n",
    "    return query_text\n",
    "\n",
    "# Instrucciones del modelo para generar la consulta\n",
    "#nl2q\n",
    "process = \"\"\"Create a query for our transaction table (go-agl-poc-itedt-p01-poc.ds_ab_poc.transactions), where we have the columns: Date, Amount, Merchant, Tag1, Tag2, Tag3, and City.\n",
    "Depending on what the user asks, create a query with the corresponding fields. If the user enters a date convert it to type yyyy/mm/dd (eg: october filter: WHERE Date '2023-10-01' AND '2023-10-31' range in query),\n",
    "and the different tag fields check in all of the columns if the filter is introduced. Do not add additional information, only the query. If you don't know if the field inputed is tag or merchant add all the conditions to the query with OR\"\"\"\n",
    "\n",
    "# Configuración de generación\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 4045,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "# Configuración de seguridad\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    "# Function to continuously process user input\n",
    "def interactive_query_processing():\n",
    "    while True:\n",
    "        # Ask for user input\n",
    "        user_input = input(\"Escribe tu pregunta: \")\n",
    "\n",
    "        # Exit condition\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "\n",
    "        # Process the input\n",
    "        processing_method = handle_input(user_input)\n",
    "        print(f\"Processing method: {processing_method}\")\n",
    "\n",
    "        filtered_words = filter_input(user_input,merchants, tags, cities)\n",
    "        print(f\"Filtered words: {filtered_words}\")\n",
    "\n",
    "        # Generate the SQL query\n",
    "        if processing_method == \"StringMatching\" and filtered_words:\n",
    "            #query = f\"SELECT * FROM `go-agl-poc-itedt-p01-poc.ds_ab_poc.transactions` WHERE Merchant LIKE '{user_input}' OR Tag1 LIKE '{user_input}' OR Tag2 LIKE '{user_input}' OR Tag3 LIKE '{user_input}' OR City LIKE '{user_input}'\"\n",
    "            # Split the input into words\n",
    "\n",
    "\n",
    "            # Create a WHERE clause that checks for matches for each word across the specified columns\n",
    "            conditions = []\n",
    "            for word in filtered_words:\n",
    "                condition = f\"\"\"\n",
    "                Merchant LIKE '%{word}%' OR\n",
    "                Tag1 LIKE '%{word}%' OR\n",
    "                Tag2 LIKE '%{word}%' OR\n",
    "                Tag3 LIKE '%{word}%' OR\n",
    "                City LIKE '%{word}%'\n",
    "                \"\"\"\n",
    "                conditions.append(f\"({condition})\")\n",
    "            print(\"The conditions are\", conditions)\n",
    "            # Combine conditions with AND to ensure all words are matched\n",
    "            where_clause = \" AND \".join(conditions)\n",
    "\n",
    "            # Generate the final query\n",
    "            query = f\"SELECT * FROM `go-agl-poc-itedt-p01-poc.ds_ab_poc.transactions` WHERE {where_clause}\"\n",
    "\n",
    "        elif processing_method == \"StringMatching\":\n",
    "            query = generate(user_input, process)\n",
    "            query = query.replace(\"```sql\", \"\", 1)\n",
    "            query = query.replace(\"```\", \"\", 1)\n",
    "\n",
    "        else:\n",
    "          print(\"Sorry enter again:\")\n",
    "          interactive_query_processing()\n",
    "\n",
    "        print(\"Consulta SQL generada:\", query)\n",
    "\n",
    "        # Execute the query on BigQuery\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        # Execute the generated query\n",
    "        query_job = client.query(query)\n",
    "\n",
    "        results = query_job.result()\n",
    "\n",
    "        # Obtener los nombres de las columnas de la consulta\n",
    "        columns = results.schema\n",
    "        column_names = [field.name for field in columns]\n",
    "\n",
    "        # Imprimir los encabezados de la tabla\n",
    "        # Alineamos las columnas a la izquierda y con un ancho de columna ajustado para que se vea bien\n",
    "        header = \" | \".join([f\"{col:<20}\" for col in column_names])\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))  # Una línea de separación\n",
    "\n",
    "        # Imprimir los resultados en forma de tabla\n",
    "        for row in results:\n",
    "            row_values = [str(value) for value in row.values()]\n",
    "            print(\" | \".join([f\"{value:<20}\" for value in row_values]))\n",
    "\n",
    "# Run the interactive process\n",
    "interactive_query_processing()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
